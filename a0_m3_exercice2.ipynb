{
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "file_extension": ".py", 
            "version": "2.7.11", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20"
        }
    }, 
    "nbformat_minor": 0, 
    "cells": [
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "markdown", 
            "source": "# Exercise 2\n## Part 1\nNow let's calculate covariance and correlation by ourselves using ApacheSpark\n\n1st we crate two random RDD\ufffds, which shouldn't correlate at all.\n"
        }, 
        {
            "execution_count": 1, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "import random\nrddX = sc.parallelize(random.sample(range(100),100))\nrddY = sc.parallelize(random.sample(range(100),100))", 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "Now we calculate the mean, note that we explicitly cast the denominator to float in order to obtain a float instead of int"
        }, 
        {
            "execution_count": 2, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "meanX = rddX.sum()/float(rddX.count())\nmeanY = rddY.sum()/float(rddY.count())\nprint meanX\nprint meanY", 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "49.5\n49.5\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "Now we calculate the covariance"
        }, 
        {
            "execution_count": 3, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "rddXY = rddX.zip(rddY)\ncovXY = rddXY.map(lambda (x,y) : (x-meanX)*(y-meanY)).sum()/rddXY.count()\ncovXY", 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "-59.41"
                    }, 
                    "output_type": "execute_result", 
                    "execution_count": 3
                }
            ]
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "Covariance is not a normalized measure. Therefore we use it to calculate correlation. But before that we need to calculate the indivicual standard deviations first"
        }, 
        {
            "execution_count": 4, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "from math import sqrt\nn = rddXY.count()\nsdX = sqrt(rddX.map(lambda x : pow(x-meanX,2)).sum()/n)\nsdY = sqrt(rddY.map(lambda x : pow(x-meanY,2)).sum()/n)\nprint sdX\nprint sdY", 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "28.8660700477\n28.8660700477\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "Now we calculate the correlation"
        }, 
        {
            "execution_count": 5, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "corrXY = covXY / (sdX * sdY)\ncorrXY", 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "-0.0712991299129913"
                    }, 
                    "output_type": "execute_result", 
                    "execution_count": 5
                }
            ]
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Part 2\nNo we want to create a correlation matrix out of the four RDDs used in the lecture"
        }, 
        {
            "execution_count": 6, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "from pyspark.mllib.stat import Statistics\nimport random\ncolumn1 = sc.parallelize(range(100))\ncolumn2 = sc.parallelize(range(100,200))\ncolumn3 = sc.parallelize(list(reversed(range(100))))\ncolumn4 = sc.parallelize(random.sample(range(100),100))\ndata = column1.zip(column2).zip(column3).zip(column4).map(lambda (((a,b),c),d) : (a,b,c,d) ).map(lambda (a,b,c,d) : [a,b,c,d])\nprint(Statistics.corr(data))", 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "[[ 1.          1.         -1.          0.21236124]\n [ 1.          1.         -1.          0.21236124]\n [-1.         -1.          1.         -0.21236124]\n [ 0.21236124  0.21236124 -0.21236124  1.        ]]\n"
                }
            ]
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "Congratulations, you are done with Exercice 2"
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat": 4
}